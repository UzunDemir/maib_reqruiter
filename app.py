import os
import streamlit as st
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import time
import json
from PyPDF2 import PdfReader
import tempfile
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import docx
from docx import Document
import io
from concurrent.futures import ThreadPoolExecutor, as_completed

st.set_page_config(layout="wide", initial_sidebar_state="expanded")

# --- Language Settings ---
if 'language' not in st.session_state:
    st.session_state.language = 'rom'  # Default language

def get_translation(key):
    translations = {
        'rom': {
            'app_title': 'AI HR-Recruiter',
            'sidebar_title': 'MAIB AI HR-Recruiter',
            'load_vacancies': '√éncarcƒÉ ofertele de muncƒÉ pentru tine...',
            'vacancies_list': 'Lista ofertelor MAIB:',
            'upload_cv': '√éncƒÉrcƒÉ CV-ul tƒÉu (PDF, DOCX, TXT)',
            'best_matches': 'Cele mai relevante oferte pentru CV-ul tƒÉu',
            'generate_analysis': 'GenereazƒÉ analiza de potrivire',
            'detailed_analysis': 'AnalizƒÉ detaliatƒÉ a conformitƒÉ»õii',
            'download_analysis': 'DescarcƒÉ analiza (DOCX)',
            'start_interview': 'A trece interviul introductiv',
            'interview_in_progress': 'Interviul a √Ænceput! VƒÉ rog sƒÉ rƒÉspunde»õi la √ÆntrebƒÉrile de mai jos.',
            'finish_interview': 'Interviul s-a √Æncheiat',
            'start_technical': '√éncepe interviul tehnic',
            'technical_in_progress': 'Interviul tehnic a √Ænceput! VƒÉ rugƒÉm sƒÉ rƒÉspunde»õi la √ÆntrebƒÉrile de mai jos.',
            'finish_technical': 'FinalizeazƒÉ interviul tehnic',
            'technical_feedback': 'Feedback tehnic',
            'final_conclusion': 'Concluzia finalƒÉ',
            'reset_process': 'ReseteazƒÉ procesul',
            'candidate_profile': 'Profilul candidatului',
            'download_profile': 'DescarcƒÉ profilul candidatului (DOCX)',
            'current_step': 'Etapa curentƒÉ:',
            'step1': '√éncƒÉrcare CV',
            'step2': 'AnalizƒÉ potrivire',
            'step3': 'Interviu general',
            'step4': 'Interviu tehnic',
            'step5': 'Concluzie finalƒÉ'
        },
        'rus': {
            'app_title': 'AI HR-–†–µ–∫—Ä—É—Ç–µ—Ä',
            'sidebar_title': 'MAIB AI HR-–†–µ–∫—Ä—É—Ç–µ—Ä',
            'load_vacancies': '–ó–∞–≥—Ä—É–∑–∏—Ç—å –≤–∞–∫–∞–Ω—Å–∏–∏ –¥–ª—è –≤–∞—Å...',
            'vacancies_list': '–°–ø–∏—Å–æ–∫ –≤–∞–∫–∞–Ω—Å–∏–π MAIB:',
            'upload_cv': '–ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∞—à–µ —Ä–µ–∑—é–º–µ (PDF, DOCX, TXT)',
            'best_matches': '–°–∞–º—ã–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –¥–ª—è –≤–∞—à–µ–≥–æ —Ä–µ–∑—é–º–µ',
            'generate_analysis': '–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∞–Ω–∞–ª–∏–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è',
            'detailed_analysis': '–ü–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è',
            'download_analysis': '–°–∫–∞—á–∞—Ç—å –∞–Ω–∞–ª–∏–∑ (DOCX)',
            'start_interview': '–ù–∞—á–∞—Ç—å –æ–±—â–µ–µ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ',
            'interview_in_progress': '–°–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ –Ω–∞—á–∞—Ç–æ! –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –Ω–∏–∂–µ.',
            'finish_interview': '–ó–∞–≤–µ—Ä—à–∏—Ç—å —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ',
            'start_technical': '–ù–∞—á–∞—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ',
            'technical_in_progress': '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ –Ω–∞—á–∞—Ç–æ! –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –Ω–∏–∂–µ.',
            'finish_technical': '–ó–∞–≤–µ—Ä—à–∏—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ',
            'technical_feedback': '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –æ—Ç–∑—ã–≤',
            'final_conclusion': '–ó–∞–∫–ª—é—á–∏—Ç–µ–ª—å–Ω—ã–π –≤—ã–≤–æ–¥',
            'reset_process': '–°–±—Ä–æ—Å–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å',
            'candidate_profile': '–ü—Ä–æ—Ñ–∏–ª—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞',
            'download_profile': '–°–∫–∞—á–∞—Ç—å –ø—Ä–æ—Ñ–∏–ª—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ (DOCX)',
            'current_step': '–¢–µ–∫—É—â–∏–π —ç—Ç–∞–ø:',
            'step1': '–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—é–º–µ',
            'step2': '–ê–Ω–∞–ª–∏–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è',
            'step3': '–û–±—â–µ–µ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ',
            'step4': '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ',
            'step5': '–ó–∞–∫–ª—é—á–∏—Ç–µ–ª—å–Ω—ã–π –≤—ã–≤–æ–¥'
        },
        'en': {
            'app_title': 'AI HR-Recruiter',
            'sidebar_title': 'MAIB AI HR-Recruiter',
            'load_vacancies': 'Load job vacancies for you...',
            'vacancies_list': 'List of MAIB vacancies:',
            'upload_cv': 'Upload your CV (PDF, DOCX, TXT)',
            'best_matches': 'Most relevant job matches for your CV',
            'generate_analysis': 'Generate matching analysis',
            'detailed_analysis': 'Detailed compatibility analysis',
            'download_analysis': 'Download analysis (DOCX)',
            'start_interview': 'Start introductory interview',
            'interview_in_progress': 'Interview has started! Please answer the questions below.',
            'finish_interview': 'Interview completed',
            'start_technical': 'Start technical interview',
            'technical_in_progress': 'Technical interview has started! Please answer the questions below.',
            'finish_technical': 'Complete technical interview',
            'technical_feedback': 'Technical feedback',
            'final_conclusion': 'Final conclusion',
            'reset_process': 'Reset process',
            'candidate_profile': 'Candidate profile',
            'download_profile': 'Download candidate profile (DOCX)',
            'current_step': 'Current step:',
            'step1': 'CV Upload',
            'step2': 'Matching Analysis',
            'step3': 'General Interview',
            'step4': 'Technical Interview',
            'step5': 'Final Conclusion'
        }
    }
    lang = st.session_state.get('language', 'rom')
    return translations.get(lang, translations['rom']).get(key, key)


# --- Stiluri »ôi bara lateralƒÉ ---
st.markdown(f"""
    <style>
        section[data-testid="stSidebar"] {{
            background-color: #253646 !important;
        }}
        .sidebar-title {{
            color: white;
            font-size: 24px;
            font-weight: bold;
            text-align: center;
            margin-bottom: 1rem;
        }}
        .sidebar-text {{
            color: white;
        }}
        #MainMenu, footer, header {{
            display: none !important;
        }}
        .center {{
            display: flex;
            justify-content: center;
            align-items: center;
            text-align: center;
            flex-direction: column;
            margin-top: 0vh;
        }}
        .match-card {{
            border-radius: 10px;
            padding: 15px;
            margin-bottom: 15px;
            background-color: #f0f2f6;
        }}
        .match-header {{
            display: flex;
            justify-content: space-between;
            align-items: center;
        }}
        .progress-bar {{
            height: 10px;
            background-color: #e0e0e0;
            border-radius: 5px;
            margin-top: 5px;
        }}
        .progress-fill {{
            height: 100%;
            border-radius: 5px;
            background-color: #40c1ac;
        }}
        .current-step {{
            background-color: #40c1ac;
            color: white;
            padding: 10px;
            border-radius: 5px;
            margin-top: 10px;
            font-weight: bold;
        }}
    </style>
    <div class="center">
        <img src="https://www.maib.md/uploads/custom_blocks/image_1633004921_8nR1jw3Qfu_auto__0.png" width="300">
        <h1>{get_translation('app_title')}</h1>
    </div>
""", unsafe_allow_html=True)


# --- Sidebar Content ---
with st.sidebar:
    st.markdown('<div class="sidebar-title">{}</div>'.format(get_translation('sidebar_title')), unsafe_allow_html=True)
    
    # Language selector
    language = st.radio("Language / –Ø–∑—ã–∫ / LimbƒÉ:", 
                       ["rom", "rus", "en"],
                       index=["rom", "rus", "en"].index(st.session_state.language),
                       key="lang_selector",
                       horizontal=True)
    
    if language != st.session_state.language:
        st.session_state.language = language
        st.rerun()
    
    st.divider()
    
    # Current step indicator
    current_step = 1
    if 'knowledge_base' in st.session_state and st.session_state.knowledge_base.uploaded_files:
        current_step = 2
    if 'analysis' in st.session_state and st.session_state.analysis:
        current_step = 3
    if 'profile' in st.session_state and st.session_state.profile:
        current_step = 4
    if 'final_recommendation' in st.session_state and st.session_state.final_recommendation:
        current_step = 5
    
    st.markdown(f'<div class="current-step">{get_translation("current_step")} {current_step}/5</div>', unsafe_allow_html=True)
    st.markdown(f"- {get_translation(f'step{current_step}')}")
    
    st.divider()
    
    # Process description
    st.markdown("""
    <div class="sidebar-text">
    
    1. üì• <strong>{}</strong>  
   <em>{}</em>

    2. üìÑ <strong>{}</strong>  
       <em>{}</em>

    3. ü§ñ <strong>{}</strong>  
       <em>{}</em>

    4. üîç <strong>{}</strong>  
       <em>{}<br>{}</em>

    5. ‚úÖ <strong>{}</strong>  
       <em>{}</em>

    6. üó£Ô∏è <strong>{}</strong>  
       <em>{}</em>

    7. ‚ö° <strong>{}</strong>    
       <em>{}</em>

    8. üíª <strong>{}</strong>  
       <em>{}</em>

    9. üìã <strong>{}</strong>  
       <em>{}</em>
    </div>
    """.format(
        get_translation('step1'), "Agentul √ÆncarcƒÉ automat toate posturile vacante actuale de la MAIB." if st.session_state.language == 'rom' else 
        "–ê–≥–µ–Ω—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Ç–µ–∫—É—â–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ MAIB." if st.session_state.language == 'rus' else 
        "The agent automatically loads all current MAIB vacancies.",
        
        get_translation('step2'), "Utilizatorul √Æ»ôi √ÆncarcƒÉ CV-ul pentru analizƒÉ." if st.session_state.language == 'rom' else 
        "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç —Å–≤–æ–µ —Ä–µ–∑—é–º–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞." if st.session_state.language == 'rus' else 
        "The user uploads their CV for analysis.",
        
        get_translation('step3'), "Agentul analizeazƒÉ CV-ul »ôi identificƒÉ top 3 posturi relevante." if st.session_state.language == 'rom' else 
        "–ê–≥–µ–Ω—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—é–º–µ –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–æ–ø-3 –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π." if st.session_state.language == 'rus' else 
        "The agent analyzes the CV and identifies top 3 relevant positions.",
        
        get_translation('step4'), "Eviden»õiazƒÉ punctele forte ale candidatului." if st.session_state.language == 'rom' else 
        "–í—ã–¥–µ–ª—è–µ—Ç —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –∫–∞–Ω–¥–∏–¥–∞—Ç–∞." if st.session_state.language == 'rus' else 
        "Highlights the candidate's strengths.",
        
        "IdentificƒÉ punctele slabe sau lipsurile √Æn competen»õe." if st.session_state.language == 'rom' else 
        "–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –∏–ª–∏ –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞–≤—ã–∫–∞—Ö." if st.session_state.language == 'rus' else 
        "Identifies weaknesses or skill gaps.",
        
        get_translation('step5'), "DacƒÉ este interesat, candidatul √Æ»ôi exprimƒÉ acordul pentru a continua procesul." if st.session_state.language == 'rom' else 
        "–ï—Å–ª–∏ –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω, –∫–∞–Ω–¥–∏–¥–∞—Ç –≤—ã—Ä–∞–∂–∞–µ—Ç —Å–æ–≥–ª–∞—Å–∏–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å." if st.session_state.language == 'rus' else 
        "If interested, the candidate agrees to continue the process.",
        
        get_translation('step3'), "Agentul pune √ÆntrebƒÉri generale, analizeazƒÉ rƒÉspunsurile »ôi formuleazƒÉ primele concluzii." if st.session_state.language == 'rom' else 
        "–ê–≥–µ–Ω—Ç –∑–∞–¥–∞–µ—Ç –æ–±—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç—ã –∏ —Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ—Ç –ø–µ—Ä–≤—ã–µ –≤—ã–≤–æ–¥—ã." if st.session_state.language == 'rus' else 
        "The agent asks general questions, analyzes responses and formulates initial conclusions.",
        
        get_translation('step4'), "Identificarea »ôi verificarea textelor create automat pentru a asigura autenticitatea con»õinutului." if st.session_state.language == 'rom' else 
        "–í—ã—è–≤–ª–µ–Ω–∏–µ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –ø–æ–¥–ª–∏–Ω–Ω–æ—Å—Ç–∏." if st.session_state.language == 'rus' else 
        "Identifying and verifying automatically generated text to ensure content authenticity.",
        
        get_translation('step4'), "Evaluarea competen»õelor tehnice »ôi furnizarea unui feedback tehnic." if st.session_state.language == 'rom' else 
        "–û—Ü–µ–Ω–∫–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –Ω–∞–≤—ã–∫–æ–≤ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç–∑—ã–≤–∞." if st.session_state.language == 'rus' else 
        "Assessing technical skills and providing technical feedback.",
        
        get_translation('step5'), "Agentul oferƒÉ un verdict final: recomandare pentru angajare sau refuz argumentat." if st.session_state.language == 'rom' else 
        "–ê–≥–µ–Ω—Ç –≤—ã–Ω–æ—Å–∏—Ç –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã–π –≤–µ—Ä–¥–∏–∫—Ç: —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –∫ –Ω–∞–π–º—É –∏–ª–∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–∫–∞–∑." if st.session_state.language == 'rus' else 
        "The agent provides a final verdict: hiring recommendation or justified refusal."
    ), unsafe_allow_html=True)

    if st.button(get_translation('load_vacancies')):
    load_vacancies()  # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ st.session_state.vacancies_data
    st.rerun()
    # Vacancies list in alphabetical order
    if 'vacancies_data' in st.session_state and st.session_state.vacancies_data:
        st.divider()
        st.markdown(f"### üîé {get_translation('vacancies_list')}")
        st.success(f"Oferte gƒÉsite: {len(st.session_state.vacancies_data)}" if st.session_state.language == 'rom' else 
                 f"–ù–∞–π–¥–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(st.session_state.vacancies_data)}" if st.session_state.language == 'rus' else 
                 f"Found vacancies: {len(st.session_state.vacancies_data)}")
        
        # Sort vacancies alphabetically
        sorted_vacancies = sorted(st.session_state.vacancies_data, key=lambda x: x['title'])
        for vac in sorted_vacancies:
            st.markdown(
                f'<a href="{vac["url"]}" target="_blank" style="color:#40c1ac; text-decoration:none;">‚Ä¢ {vac["title"]}</a>',
                unsafe_allow_html=True
            )

st.divider()

#######################################################################
class DocumentChunk:
    def __init__(self, text, doc_name, page_num):
        self.text = text
        self.doc_name = doc_name
        self.page_num = page_num

class KnowledgeBase:
    def __init__(self):
        self.chunks = []
        self.uploaded_files = []
        self.doc_texts = []
    
    def clear(self):
        self.chunks = []
        self.doc_texts = []
        self.uploaded_files = []
    
    def split_text(self, text, max_chars=2000):
        chunks = []
        start = 0
        while start < len(text):
            end = min(start + max_chars, len(text))
            chunk = text[start:end].strip()
            if chunk:  # Skip empty chunks
                chunks.append(chunk)
            start = end
        return chunks

    def load_pdf(self, file_content, file_name):
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
                tmp_file.write(file_content)
                tmp_file_path = tmp_file.name

            with open(tmp_file_path, 'rb') as file:
                reader = PdfReader(file)
                for page_num, page in enumerate(reader.pages):
                    page_text = page.extract_text()
                    if page_text:
                        for chunk in self.split_text(page_text):
                            self.chunks.append(DocumentChunk(chunk, file_name, page_num+1))
                            self.doc_texts.append(chunk)
            self.uploaded_files.append(file_name)
            return True
        except Exception as e:
            st.error(f"Eroare la √ÆncƒÉrcarea PDF: {str(e)}")
            return False
        finally:
            if os.path.exists(tmp_file_path):
                os.unlink(tmp_file_path)

    def load_docx(self, file_content, file_name):
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix='.docx') as tmp_file:
                tmp_file.write(file_content)
                tmp_file_path = tmp_file.name

            doc = docx.Document(tmp_file_path)
            full_text = []
            for para in doc.paragraphs:
                text = para.text.strip()
                if text:  # Skip empty paragraphs
                    full_text.append(text)
            text = "\n".join(full_text)
            for chunk in self.split_text(text):
                self.chunks.append(DocumentChunk(chunk, file_name, 0))
                self.doc_texts.append(chunk)
            self.uploaded_files.append(file_name)
            return True
        except Exception as e:
            st.error(f"Eroare la √ÆncƒÉrcarea DOCX: {str(e)}")
            return False
        finally:
            if os.path.exists(tmp_file_path):
                os.unlink(tmp_file_path)

    def load_txt(self, file_content, file_name):
        try:
            text = file_content.decode('utf-8', errors='ignore')
            for chunk in self.split_text(text):
                self.chunks.append(DocumentChunk(chunk, file_name, 0))
                self.doc_texts.append(chunk)
            self.uploaded_files.append(file_name)
            return True
        except Exception as e:
            st.error(f"Eroare la √ÆncƒÉrcarea TXT: {str(e)}")
            return False

    def load_file(self, uploaded_file):
        name = uploaded_file.name.lower()
        content = uploaded_file.read()
        if name.endswith('.pdf'):
            return self.load_pdf(content, uploaded_file.name)
        elif name.endswith('.docx'):
            return self.load_docx(content, uploaded_file.name)
        elif name.endswith('.txt'):
            return self.load_txt(content, uploaded_file.name)
        else:
            st.warning(f"Formatul fi»ôierului {uploaded_file.name} nu este suportat.")
            return False

    def get_all_text(self):
        return "\n\n".join(self.doc_texts)
#########################################################

# --- Initialize knowledge base ---
if 'knowledge_base' not in st.session_state:
    st.session_state.knowledge_base = KnowledgeBase()

if 'vacancies_data' not in st.session_state:
    st.session_state.vacancies_data = []

if st.button(get_translation('load_vacancies')):
    load_vacancies()  # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ st.session_state.vacancies_data
    st.rerun()  # –î–æ–±–∞–≤—å—Ç–µ —ç—Ç–æ, —á—Ç–æ–±—ã —Å—Ä–∞–∑—É –æ–±–Ω–æ–≤–∏—Ç—å –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å

# --- Scrape vacancies function remains the same ---
# [Previous scrape_vacancy and load_vacancies functions]
###########################################################################################
##############################
# √éncƒÉrcare oferte de pe rabota.md
def scrape_vacancy(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        resp = requests.get(url, headers=headers, timeout=10)
        resp.raise_for_status()
        soup_vac = BeautifulSoup(resp.text, 'html.parser')

        title_tag = soup_vac.find('h1')
        title = title_tag.get_text(strip=True) if title_tag else 'Titlu indisponibil'

        vacancy_content = soup_vac.find('div', class_='vacancy-content')
        description = vacancy_content.get_text(separator='\n', strip=True) if vacancy_content else 'Descriere indisponibilƒÉ'

        return {'url': url, 'title': title, 'description': description}
    except Exception as e:
        st.error(f"Eroare la preluarea ofertei {url}: {str(e)}")
        return None

#######################################################################################################################
from concurrent.futures import ThreadPoolExecutor, as_completed

def load_vacancies():
    base_url = "https://www.rabota.md/ru/companies/moldova-agroindbank#vacancies"
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    with st.spinner("Se √ÆncarcƒÉ ofertele de muncƒÉ..."):
        try:
            response = requests.get(base_url, headers=headers, timeout=10)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')

            links = soup.find_all('a', class_='vacancyShowPopup')
            urls = [urljoin(base_url, a['href']) for a in links]

            vacancies_data = []
            progress_bar = st.progress(0)
            status_text = st.empty()

            total = len(urls)
            done = 0

            with ThreadPoolExecutor(max_workers=5) as executor:
                future_to_url = {executor.submit(scrape_vacancy, url): url for url in urls}
                
                for future in as_completed(future_to_url):
                    result = future.result()
                    if result:
                        vacancies_data.append(result)
                        done += 1
                        progress_bar.progress(done / total)
                        status_text.text(f"[{done}/{total}] OfertƒÉ √ÆncƒÉrcatƒÉ: {result['title']}")

            st.session_state.vacancies_data = vacancies_data
            st.success(f"Au fost √ÆncƒÉrcate {len(vacancies_data)} oferte de muncƒÉ!")

        except Exception as e:
            st.error(f"Eroare la √ÆncƒÉrcarea ofertelor: {str(e)}")
##########################################################################################################################################

if st.button(get_translation('load_vacancies')):
    load_vacancies()

# --- CV Upload Section ---
st.markdown(f"### üìÑ {get_translation('upload_cv')}")
uploaded_files = st.file_uploader(get_translation('upload_cv'), type=['pdf', 'docx', 'txt'], accept_multiple_files=True)

if uploaded_files:
    kb = st.session_state.knowledge_base
    kb.clear()
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, uploaded_file in enumerate(uploaded_files):
        success = kb.load_file(uploaded_file)
        progress = (i + 1) / len(uploaded_files)
        progress_bar.progress(progress)
        status_text.text(f"Se proceseazƒÉ fi»ôierul {i+1}/{len(uploaded_files)}: {uploaded_file.name}" if st.session_state.language == 'rom' else
                        f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è —Ñ–∞–π–ª {i+1}/{len(uploaded_files)}: {uploaded_file.name}" if st.session_state.language == 'rus' else
                        f"Processing file {i+1}/{len(uploaded_files)}: {uploaded_file.name}")
    
    st.session_state.knowledge_base = kb
    st.success(f"Au fost √ÆncƒÉrcate {len(uploaded_files)} fi»ôiere!" if st.session_state.language == 'rom' else
              f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(uploaded_files)}" if st.session_state.language == 'rus' else
              f"Uploaded files: {len(uploaded_files)}")

if not st.session_state.knowledge_base.uploaded_files:
    st.info("Te rugƒÉm sƒÉ √Æncarci un CV pentru analizƒÉ" if st.session_state.language == 'rom' else
           "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ä–µ–∑—é–º–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞" if st.session_state.language == 'rus' else
           "Please upload a CV for analysis")
    st.stop()

# --- Best Matches Section ---
st.markdown(f"### üîç {get_translation('best_matches')}")

cv_text = st.session_state.knowledge_base.get_all_text()
vacancies = st.session_state.vacancies_data

if not vacancies:
    st.warning("Nu existƒÉ oferte de muncƒÉ disponibile. Te rugƒÉm sƒÉ √Æncarci ofertele mai √Ænt√¢i." if st.session_state.language == 'rom' else
              "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∞–∫–∞–Ω—Å–∏–∏." if st.session_state.language == 'rus' else
              "No job vacancies available. Please load vacancies first.")
    st.stop()

# Analiza potrivirilor
st.markdown("### üîç Cele mai relevante oferte pentru CV-ul tƒÉu")

cv_text = st.session_state.knowledge_base.get_all_text()
vacancies = st.session_state.vacancies_data

if not vacancies:
    st.warning("Nu existƒÉ oferte de muncƒÉ disponibile. Te rugƒÉm sƒÉ √Æncarci ofertele mai √Ænt√¢i.")
    st.stop()

# Procesare avansatƒÉ a textelor
vacancy_texts = [f"{vac['title']}\n{vac['description']}" for vac in vacancies]
documents = [cv_text] + vacancy_texts

# TF-IDF √ÆmbunƒÉtƒÉ»õit
vectorizer = TfidfVectorizer(
    stop_words=None,
    ngram_range=(1, 2),  # Include bigrame pentru mai mult context
    max_features=5000
)

##############################################################################
################################
def check_if_ai_generated(answer_text):
    prompt = f"""
    EvalueazƒÉ dacƒÉ urmƒÉtorul rƒÉspuns a fost generat de un om sau de o re»õea neuronalƒÉ (cum ar fi ChatGPT).

    RƒÉspuns:
    \"\"\"
    {answer_text}
    \"\"\"

    RƒÉspunde doar cu una dintre op»õiuni:
    - uman
    - AI
    """

    response = requests.post(
        url,
        headers=headers,
        json={
            "model": "deepseek-chat",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.2
        }
    )

    result = response.json()['choices'][0]['message']['content'].strip().lower()
    return result

###########################################################




# --- –ê–Ω–∞–ª–∏–∑ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –≤–∞–∫–∞–Ω—Å–∏–π ---
try:
    with st.spinner("Se analizeazƒÉ potrivirile..."):
        vectorizer = TfidfVectorizer()
        tfidf_matrix = vectorizer.fit_transform(documents)
        similarity_scores = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:]).flatten()

    score_min, score_max = similarity_scores.min(), similarity_scores.max()
    if score_max - score_min > 0:
        normalized_scores = (similarity_scores - score_min) / (score_max - score_min) * 100
    else:
        normalized_scores = np.zeros_like(similarity_scores)

    normalized_scores = np.clip(normalized_scores, 0, 100)

    top_indices = similarity_scores.argsort()[::-1][:3]

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º top_indices –≤ —Å–µ—Å—Å–∏—é, —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–∞–ª—å—à–µ
    st.session_state.top_indices = top_indices

    for idx in top_indices:
        vac = vacancies[idx]
        score = normalized_scores[idx]

        with st.container():
            st.markdown(f"""
            <div class="match-card">
                <div class="match-header">
                    <h3><a href="{vac['url']}" target="_blank" style="text-decoration:none; color:inherit;">{vac['title']}</a></h3>
                    <h4>{score:.0f}% potrivire</h4>
                </div>
                <div class="progress-bar">
                    <div class="progress-fill" style="width: {score}%"></div>
                </div>
            </div>
            """, unsafe_allow_html=True)

        st.write("---")

except Exception as e:
    st.error(f"Eroare la analiza potrivirilor: {str(e)}")

# --- API Configuration ---
api_key = st.secrets.get("DEEPSEEK_API_KEY")
if not api_key:
    st.error("API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–æ–±–∞–≤—å—Ç–µ –µ–≥–æ –≤ Secrets.")
    st.stop()

url = "https://api.deepseek.com/v1/chat/completions"
headers = {
    "Authorization": f"Bearer {api_key}",
    "Content-Type": "application/json"
}

# [Rest of your code with AI-generated content remains the same]
# [Previous implementations of check_if_ai_generated, generate_interview_questions, etc.]

# --- Update all UI elements to use get_translation() ---
# For example:
# st.button(get_translation('generate_analysis'))
# st.markdown(f"## üìä {get_translation('detailed_analysis')}")
# etc.

# [Continue with the rest of your application code, replacing all UI text with get_translation() calls]

# –ò—Å–ø–æ–ª—å–∑—É–µ–º top_indices –∏–∑ —Å–µ—Å—Å–∏–∏, –µ—Å–ª–∏ –µ—Å—Ç—å
top_indices = st.session_state.get("top_indices", [])
if len(top_indices) > 0:
    best_match_idx = top_indices[0]
    best_match_vacancy = vacancies[best_match_idx]

    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∫–Ω–æ–ø–∫—É –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞
    if st.button("üîç GenereazƒÉ analiza de potrivire"):
        prompt = f"""
        AnalizeazƒÉ coresponden»õa dintre CV-ul candidatului »ôi oferta de muncƒÉ.
        Mai √Ænt√¢i voi furniza CV-ul, apoi descrierea postului.

        CV-ul candidatului:
        {cv_text}
        
        Descrierea postului:
        {best_match_vacancy['description']}
        
        VƒÉ rog sƒÉ efectua»õi analiza conform urmƒÉtoarei structuri:

        1. Punctele forte ale CV-ului (potrivirea exactƒÉ cu cerin»õele postului)
        2. Punctele slabe sau lacunele din CV (unde candidatul nu corespunde)
        3. RecomandƒÉri concrete pentru √ÆmbunƒÉtƒÉ»õirea CV-ului √Æn vederea acestei pozi»õii
        4. Procentajul general de potrivire (evaluat pe o scarƒÉ de la 0 la 100%)
        5. Fi»õi c√¢t mai concret, cita»õi cerin»õele specifice din descrierea postului »ôi punctele din CV.
        """

        try:
            with st.spinner("GenerƒÉm o analizƒÉ detaliatƒÉ‚Ä¶"):
                data = {
                    "model": "deepseek-chat",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.3
                }

                response = requests.post(url, headers=headers, json=data)
                response.raise_for_status()

                result = response.json()
                analysis = result['choices'][0]['message']['content']

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ –≤ —Å–µ—Å—Å–∏—é, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–æ–ø–∞–¥–∞–ª
                st.session_state.analysis = analysis

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ API: {str(e)}")

# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∞–Ω–∞–ª–∏–∑, –µ—Å–ª–∏ –æ–Ω —É–∂–µ –µ—Å—Ç—å –≤ —Å–µ—Å—Å–∏–∏
if 'analysis' in st.session_state and st.session_state.analysis:
    st.markdown("## üìä AnalizƒÉ detaliatƒÉ a conformitƒÉ»õii")
    st.markdown(st.session_state.analysis)

    # –ö–Ω–æ–ø–∫–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞ –≤ docx
    def create_word_document(text):
        doc = Document()
        doc.add_heading('AnalizƒÉ detaliatƒÉ a conformitƒÉ»õii', 0)
        for line in text.split('\n'):
            if line.strip():
                if line.startswith('##'):
                    doc.add_heading(line.replace('##', '').strip(), level=1)
                elif line.startswith('#'):
                    doc.add_heading(line.replace('#', '').strip(), level=2)
                else:
                    doc.add_paragraph(line)
        return doc

    doc = create_word_document(st.session_state.analysis)
    bio = io.BytesIO()
    doc.save(bio)
    bio.seek(0)

    st.download_button(
        label="üíæ DescarcƒÉ analiza (DOCX)",
        data=bio,
        file_name="analiza_potrivire.docx",
        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    )
else:
    st.info("ApƒÉsa»õi butonul pentru a genera analiza de potrivire.")

# --- –ò–Ω—Ç–µ—Ä–≤—å—é ---

def generate_interview_questions(cv_text):
    prompt = f"""
    GenereazƒÉ 10 √ÆntrebƒÉri pentru un interviu introductiv pe baza acestui CV:
    {cv_text}

    Cerin»õe:

    1. 3 √ÆntrebƒÉri despre experien»õa profesionalƒÉ
    2. 2 √ÆntrebƒÉri despre abilitƒÉ»õile tehnice
    3. 1 √Æntrebare despre punctele slabe
    4. 1 √Æntrebare despre motiva»õie
    5. 1 √Æntrebare despre a»ôteptƒÉrile salariale
    6. 2 √ÆntrebƒÉri biografice

    √éntrebƒÉrile trebuie sƒÉ fie specifice »ôi legate de CV

    ReturneazƒÉ doar o listƒÉ numerotatƒÉ de √ÆntrebƒÉri, fƒÉrƒÉ explica»õii suplimentare.
    """

    response = requests.post(
        url,
        headers=headers,
        json={
            "model": "deepseek-chat",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.3
        }
    )
    return response.json()['choices'][0]['message']['content']

def generate_candidate_profile(questions, answers):
    prompt = f"""
    Pe baza acestor √ÆntrebƒÉri »ôi rƒÉspunsuri, creeazƒÉ un profil al candidatului:

    √éntrebƒÉri:
    {questions}

    RƒÉspunsuri:

    {answers}

    –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ—Ñ–∏–ª—è:
    ### üßë‚Äçüíª Portret profesional
    - Competen»õe principale
    - Experien»õƒÉ relevantƒÉ
    - ExpertizƒÉ tehnicƒÉ

    ### üéØ Motiva»õie »ôi obiective
    - Interese profesionale
    - A»ôteptƒÉri de la job

    ### üìà Puncte forte
    - Avantaje cheie
    - Competen»õe unice

    ### ‚ö†Ô∏è Zone de dezvoltare
    - Puncte slabe
    - Competen»õe de √ÆmbunƒÉtƒÉ»õit

    ### üí∞ A»ôteptƒÉri privind compensa»õia
    - A»ôteptƒÉri salariale
    - Disponibilitate pentru negociere
    """

    response = requests.post(
        url,
        headers=headers,
        json={
            "model": "deepseek-chat",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.2
        }
    )
    return response.json()['choices'][0]['message']['content']

st.title("ü§ñ AI HR-Recruiter: Interviu introductiv")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏–Ω—Ç–µ—Ä–≤—å—é
if 'interview_started' not in st.session_state:
    st.session_state.interview_started = False
    st.session_state.questions = None
    st.session_state.answers = {}
    st.session_state.profile = None

if not st.session_state.interview_started:
    if st.button("üé§ A trece interviul introductiv", type="primary"):
        with st.spinner("PregƒÉtim √ÆntrebƒÉrile..."):
            st.session_state.questions = generate_interview_questions(documents[0])
            st.session_state.interview_started = True
        st.rerun()
        

if st.session_state.interview_started:
    st.success("Interviul a √Ænceput! VƒÉ rog sƒÉ rƒÉspunde»õi la √ÆntrebƒÉrile de mai jos.")

    questions_list = [q for q in st.session_state.questions.split('\n') if q.strip()]
    for i, question in enumerate(questions_list[:10]):
        st.session_state.answers[i] = st.text_area(
            label=f"**{i+1}:** {question}",
            value=st.session_state.answers.get(i, ""),
            key=f"answer_{i}"
        )

    ########################################################################################

    if st.button("‚úÖ Interviul s-a √Æncheiat", type="primary"):
    
        with st.spinner("AnalizƒÉm rƒÉspunsurile..."):
            questions_list = [q for q in st.session_state.questions.split('\n') if q.strip()]
            
            formatted_answers = "\n".join(
                [
                    f"{i+1}. {q}\n   –û—Ç–≤–µ—Ç: {st.session_state.answers.get(i, '').strip() or 'Candidatul nu a putut rƒÉspunde la aceastƒÉ √Æntrebare'}"
                    for i, q in enumerate(questions_list[:10])
                ]
            )
    
            # üß† –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ò–ò-—Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
            suspicious_flags = []
            for i, q in enumerate(questions_list[:10]):
                answer = st.session_state.answers.get(i, '').strip()
                verdict = check_if_ai_generated(answer)  # –ò—Å–ø–æ–ª—å–∑—É–π —Å–≤–æ—é LLM-—Ñ—É–Ω–∫—Ü–∏—é
                if 'ai' in verdict.lower():
                    suspicious_flags.append((i+1, verdict))
    
            if suspicious_flags:
                st.warning("üö® Unele rƒÉspunsuri par a fi generate de AI:")
                for q_num, reason in suspicious_flags:
                    st.markdown(f"- √éntrebarea {q_num}: rƒÉspuns suspectat ca fiind generat de AI")
    
            # üßæ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ—Ñ–∏–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
            st.session_state.profile = generate_candidate_profile(
                st.session_state.questions,
                formatted_answers
            )
    
        st.success("Interviul s-a √Æncheiat!")
        st.balloons()
        st.rerun()


    

      

if st.session_state.profile:
    st.markdown("## üìå Profilul candidatului")
    st.markdown(st.session_state.profile)

    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ DOCX –ø—Ä–æ—Ñ–∏–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
    def create_word_document_profile(profile_text):
        doc = Document()
        doc.add_heading('Profil Candidat', 0)
        for line in profile_text.split('\n'):
            if line.strip():
                if line.startswith('###'):
                    doc.add_heading(line.replace('###', '').strip(), level=2)
                else:
                    doc.add_paragraph(line)
        return doc

    doc_profile = create_word_document_profile(st.session_state.profile)
    bio_profile = io.BytesIO()
    doc_profile.save(bio_profile)
    bio_profile.seek(0)

    st.download_button(
        label="üíæ DescarcƒÉ profilul candidatului (DOCX)",
        data=bio_profile,
        file_name="profil_candidat.docx",
        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    )


###########################################################################################################
# --- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã (–≥–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ LLM) ---
def generate_technical_questions(cv_text):
    prompt = f"""
    GenereazƒÉ 5 √ÆntrebƒÉri tehnice specifice pe baza acestui CV:
    {cv_text}

    √éntrebƒÉrile trebuie sƒÉ testeze competen»õele tehnice ale candidatului.
    ReturneazƒÉ doar o listƒÉ numerotatƒÉ de √ÆntrebƒÉri, fƒÉrƒÉ alte explica»õii.
    """
    response = requests.post(
        url,
        headers=headers,
        json={
            "model": "deepseek-chat",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.3
        }
    )
    return response.json()['choices'][0]['message']['content']

# --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ —Ñ–∏–¥–±–µ–∫–∞ –ø–æ –æ—Ç–≤–µ—Ç–∞–º ---
def generate_technical_feedback(questions, answers):
    prompt = f"""
    Pe baza urmƒÉtoarelor √ÆntrebƒÉri tehnice »ôi rƒÉspunsuri, oferƒÉ un feedback detaliat »ôi un scor evaluativ (0-10) pentru competen»õele tehnice ale candidatului.

    √éntrebƒÉri:
    {questions}

    RƒÉspunsuri:
    {answers}

    FormateazƒÉ rƒÉspunsul astfel:

    Feedback detaliat:
    [text]

    Scor tehnic: [numƒÉr de la 0 la 10]
    """
    response = requests.post(
        url,
        headers=headers,
        json={
            "model": "deepseek-chat",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.2
        }
    )
    return response.json()['choices'][0]['message']['content']

# --- –ò—Ç–æ–≥–æ–≤–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è ---
def generate_final_recommendation(profile, tech_feedback, ai_flags_count):
    prompt = f"""
    Av√¢nd urmƒÉtorul profil al candidatului:

    {profile}

    Feedback tehnic:

    {tech_feedback}

    NumƒÉr de rƒÉspunsuri suspectate ca fiind generate de AI: {ai_flags_count}

    Pe baza acestor informa»õii, formuleazƒÉ o concluzie finalƒÉ clarƒÉ cu una din urmƒÉtoarele recomandƒÉri:
    - Recomandare pentru angajare
    - Recomandare cu rezerve
    - Refuz argumentat

    Include argumentele principale pentru decizie.
    """
    response = requests.post(
        url,
        headers=headers,
        json={
            "model": "deepseek-chat",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.2
        }
    )
    return response.json()['choices'][0]['message']['content']

# --- Streamlit UI ---

st.title("ü§ñ AI HR-Recruiter: Interviu tehnic »ôi concluzie finalƒÉ")

if 'tech_interview_started' not in st.session_state:
    st.session_state.tech_interview_started = False
    st.session_state.tech_questions = None
    st.session_state.tech_answers = {}
    st.session_state.tech_feedback = None
    st.session_state.final_recommendation = None

# –ö–Ω–æ–ø–∫–∞ –Ω–∞—á–∞–ª–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤—å—é
if not st.session_state.tech_interview_started and st.session_state.interview_started:
    if st.button("üíª √éncepe interviul tehnic"):
        with st.spinner("PregƒÉtim √ÆntrebƒÉrile tehnice..."):
            st.session_state.tech_questions = generate_technical_questions(documents[0])
            st.session_state.tech_interview_started = True
        st.rerun()

# –§–æ—Ä–º–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤—å—é
if st.session_state.tech_interview_started:
    st.success("Interviul tehnic a √Ænceput! VƒÉ rugƒÉm sƒÉ rƒÉspunde»õi la √ÆntrebƒÉrile de mai jos.")

    tech_q_list = [q for q in st.session_state.tech_questions.split('\n') if q.strip()]
    for i, question in enumerate(tech_q_list[:5]):
        st.session_state.tech_answers[i] = st.text_area(
            label=f"**{i+1}:** {question}",
            value=st.session_state.tech_answers.get(i, ""),
            key=f"tech_answer_{i}"
        )

    if st.button("‚úÖ FinalizeazƒÉ interviul tehnic"):
        with st.spinner("AnalizƒÉm rƒÉspunsurile tehnice..."):
            formatted_tech_answers = "\n".join(
                [
                    f"{i+1}. {q}\n   RƒÉspuns: {st.session_state.tech_answers.get(i, '').strip() or 'Nu a rƒÉspuns'}"
                    for i, q in enumerate(tech_q_list[:5])
                ]
            )

            # –ê–Ω–∞–ª–∏–∑ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤ —á–µ—Ä–µ–∑ LLM
            st.session_state.tech_feedback = generate_technical_feedback(
                st.session_state.tech_questions,
                formatted_tech_answers
            )

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ AI-—Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ –≤—Å–µ—Ö —ç—Ç–∞–ø–æ–≤ (–∑–¥–µ—Å—å –≤—ã–∑—ã–≤–∞–µ–º —Å–≤–æ—é —Ñ—É–Ω–∫—Ü–∏—é)
            suspicious_flags = []
            all_answers = list(st.session_state.answers.values()) + list(st.session_state.tech_answers.values())
            for idx, ans in enumerate(all_answers):
                verdict = check_if_ai_generated(ans)
                if 'ai' in verdict.lower():
                    suspicious_flags.append((idx+1, verdict))

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤–æ–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            st.session_state.final_recommendation = generate_final_recommendation(
                st.session_state.profile,
                st.session_state.tech_feedback,
                len(suspicious_flags)
            )
        st.success("Interviul tehnic s-a √Æncheiat!")
        st.balloons()
        st.rerun()

# # –í—ã–≤–æ–¥ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ —Ñ–∏–¥–±–µ–∫–∞ –∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–µ—Ä–¥–∏–∫—Ç–∞
# if st.session_state.tech_feedback:
#     st.markdown("## üíª Feedback tehnic")
#     st.markdown(st.session_state.tech_feedback)

# if st.session_state.final_recommendation:
#     st.markdown("## üìã Concluzia finalƒÉ")
#     st.markdown(st.session_state.final_recommendation)

#     if st.button("üîÑ ReseteazƒÉ procesul"):
#         for key in ['interview_started', 'questions', 'answers', 'profile',
#                     'tech_interview_started', 'tech_questions', 'tech_answers', 'tech_feedback', 'final_recommendation']:
#             if key in st.session_state:
#                 del st.session_state[key]
#         st.rerun()


# # # –í—ã–≤–æ–¥ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ —Ñ–∏–¥–±–µ–∫–∞ –∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–µ—Ä–¥–∏–∫—Ç–∞
# # if st.session_state.final_recommendation:
# #     st.markdown("## üìã Concluzia finalƒÉ")
# #     st.markdown(st.session_state.final_recommendation)
    
#     # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
#     def create_final_report():
#         doc = Document()
        
#         # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ—Ñ–∏–ª—å
#         doc.add_heading('Profil Candidat', 0)
#         for line in st.session_state.profile.split('\n'):
#             if line.strip():
#                 if line.startswith('###'):
#                     doc.add_heading(line.replace('###', '').strip(), level=2)
#                 else:
#                     doc.add_paragraph(line)
        
#         # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Ñ–∏–¥–±–µ–∫
#         doc.add_heading('Feedback Tehnic', 1)
#         doc.add_paragraph(st.session_state.tech_feedback)
        
#         # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–∫–ª—é—á–µ–Ω–∏–µ
#         doc.add_heading('Concluzie FinalƒÉ', 1)
#         doc.add_paragraph(st.session_state.final_recommendation)
        
#         return doc
    
#     # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
#     doc_report = create_final_report()
#     bio_report = io.BytesIO()
#     doc_report.save(bio_report)
#     bio_report.seek(0)
    
#     st.download_button(
#         label="üíæ DescarcƒÉ raportul complet (DOCX)",
#         data=bio_report,
#         file_name="raport_interviu.docx",
#         mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
#     )

#     if st.button("üîÑ ReseteazƒÉ procesul"):
#         for key in ['interview_started', 'questions', 'answers', 'profile',
#                    'tech_interview_started', 'tech_questions', 'tech_answers', 
#                    'tech_feedback', 'final_recommendation']:
#             if key in st.session_state:
#                 del st.session_state[key]
#         st.rerun()


# --- –ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤—å—é ---

# 1. –°–Ω–∞—á–∞–ª–∞ –≤—ã–≤–æ–¥–∏–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Ñ–∏–¥–±–µ–∫ (–µ—Å–ª–∏ –µ—Å—Ç—å)
if st.session_state.tech_feedback:
    st.markdown("## üíª Feedback tehnic")
    st.markdown(st.session_state.tech_feedback)

# 2. –ó–∞—Ç–µ–º –≤—ã–≤–æ–¥–∏–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é (–µ—Å–ª–∏ –µ—Å—Ç—å)
if st.session_state.final_recommendation:
    st.markdown("## üìã Concluzia finalƒÉ")
    st.markdown(st.session_state.final_recommendation)
    
    # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (–≤–∫–ª—é—á–∞—è —Ñ–∏–¥–±–µ–∫ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é)
    def create_final_report():
        doc = Document()
        doc.add_heading("Raport complet candidat", 0)
        
        # –ü—Ä–æ—Ñ–∏–ª—å
        doc.add_heading("Profil candidat", 1)
        for line in st.session_state.profile.split('\n'):
            if line.strip():
                if line.startswith('###'):
                    doc.add_heading(line.replace('###', '').strip(), 2)
                else:
                    doc.add_paragraph(line)
        
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Ñ–∏–¥–±–µ–∫
        doc.add_heading("Feedback tehnic", 1)
        doc.add_paragraph(st.session_state.tech_feedback)
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è
        doc.add_heading("Recomandare finalƒÉ", 1)
        doc.add_paragraph(st.session_state.final_recommendation)
        
        return doc

    # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    report_doc = create_final_report()
    report_bio = io.BytesIO()
    report_doc.save(report_bio)
    report_bio.seek(0)
    
    st.download_button(
        label="üíæ DescarcƒÉ raport complet (DOCX)",
        data=report_bio,
        file_name="raport_candidat.docx",
        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    )

    # –ö–Ω–æ–ø–∫–∞ —Å–±—Ä–æ—Å–∞
    if st.button("üîÑ ReseteazƒÉ procesul"):
        for key in st.session_state.keys():
            del st.session_state[key]
        st.rerun()
