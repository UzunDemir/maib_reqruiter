import streamlit as st
from PyPDF2 import PdfReader
import docx
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import os

st.set_page_config(page_title="MAIB CV Matcher", layout="wide")
st.title("MAIB CV Matcher")

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —á—Ç–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF
def read_pdf(file):
    reader = PdfReader(file)
    text = ""
    for page in reader.pages:
        text += page.extract_text() or ""
    return text

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —á—Ç–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ DOCX
def read_docx(file):
    doc = docx.Document(file)
    return "\n".join([para.text for para in doc.paragraphs])

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —á—Ç–µ–Ω–∏—è –≤—Å–µ—Ö –≤–∞–∫–∞–Ω—Å–∏–π
def read_job_descriptions(folder_path="job_descriptions"):
    jobs = []
    filenames = []
    for filename in os.listdir(folder_path):
        path = os.path.join(folder_path, filename)
        if filename.endswith(".pdf"):
            with open(path, "rb") as f:
                jobs.append(read_pdf(f))
                filenames.append(filename)
        elif filename.endswith(".docx"):
            jobs.append(read_docx(path))
            filenames.append(filename)
    return jobs, filenames

# –§—É–Ω–∫—Ü–∏—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
def find_most_relevant_jobs(cv_text, job_texts, job_filenames, top_n=3):
    texts = [cv_text] + job_texts
    vectorizer = TfidfVectorizer(stop_words="english")
    tfidf_matrix = vectorizer.fit_transform(texts)
    similarities = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:]).flatten()
    top_indices = similarities.argsort()[-top_n:][::-1]
    return [(job_filenames[i], similarities[i]) for i in top_indices]

# –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ–∑—é–º–µ
uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–≤–æ—ë —Ä–µ–∑—é–º–µ (PDF –∏–ª–∏ DOCX)", type=["pdf", "docx"])

if uploaded_file:
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
    if uploaded_file.name.endswith(".pdf"):
        cv_text = read_pdf(uploaded_file)
    elif uploaded_file.name.endswith(".docx"):
        cv_text = read_docx(uploaded_file)

    st.subheader("üßæ –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Ä–µ–∑—é–º–µ:")
    st.write(cv_text[:1000] + "..." if len(cv_text) > 1000 else cv_text)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏ –∏ –∏—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ
    job_texts, job_filenames = read_job_descriptions()
    relevant_jobs = find_most_relevant_jobs(cv_text, job_texts, job_filenames)

    st.subheader("üîé –¢–æ–ø —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π:")
    for job_file, score in relevant_jobs:
        st.markdown(f"- **{job_file}** ‚Äî —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: `{score:.2f}`")

